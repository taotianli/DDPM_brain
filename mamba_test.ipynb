{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from einops import rearrange\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from zeta.nn.modules.simple_mamba import MambaBlock\n",
    "\n",
    "\n",
    "class UMambaBlock_2D(nn.Module):\n",
    "    \"\"\"\n",
    "    UMambaBlock_2D is a 4d Mamba block that can be used as a building block for a 4d visual model\n",
    "    From the paper: https://arxiv.org/pdf/2401.04722.pdf\n",
    "\n",
    "    Args:\n",
    "        dim (int): The input dimension.\n",
    "        dim_inner (Optional[int]): The inner dimension. If not provided, it is set to dim * expand.\n",
    "        depth (int): The depth of the Mamba block.\n",
    "        d_state (int): The state dimension. Default is 16.\n",
    "        expand (int): The expansion factor. Default is 2.\n",
    "        dt_rank (Union[int, str]): The rank of the temporal difference (Δ) tensor. Default is \"auto\".\n",
    "        d_conv (int): The dimension of the convolutional kernel. Default is 4.\n",
    "        conv_bias (bool): Whether to include bias in the convolutional layer. Default is True.\n",
    "        bias (bool): Whether to include bias in the linear layers. Default is False.\n",
    "\n",
    "    Examples::\n",
    "        import torch\n",
    "        # img:         B, C, H, W\n",
    "        img_tensor = torch.randn(1, 64, 10, 10)\n",
    "\n",
    "        # Initialize Mamba block\n",
    "        block = UMambaBlock(dim=64, depth=1)\n",
    "\n",
    "        # Forward pass\n",
    "        y = block(img_tensor)\n",
    "        print(y.shape)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int = None,\n",
    "        depth: int = 5,\n",
    "        d_state: int = 16,\n",
    "        expand: int = 2,\n",
    "        d_conv: int = 4,\n",
    "        conv_bias: bool = True,\n",
    "        bias: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.depth = depth\n",
    "        self.d_state = d_state\n",
    "        self.expand = expand\n",
    "        self.d_conv = d_conv\n",
    "        self.conv_bias = conv_bias\n",
    "        self.bias = bias\n",
    "\n",
    "        # If dt_rank is not provided, set it to ceil(dim / d_state)\n",
    "        dt_rank = math.ceil(self.dim / 16)\n",
    "        self.dt_rank = dt_rank\n",
    "\n",
    "        # If dim_inner is not provided, set it to dim * expand\n",
    "        dim_inner = dim * expand\n",
    "        self.dim_inner = dim_inner\n",
    "\n",
    "        # If dim_inner is not provided, set it to dim * expand\n",
    "        self.in_proj = nn.Linear(dim, dim_inner, bias=False)\n",
    "        self.out_proj = nn.Linear(dim_inner, dim, bias=False)\n",
    "\n",
    "        # Implement 2d convolutional layer\n",
    "        # 3D depthwise convolution\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=dim,\n",
    "            out_channels=dim_inner,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            stride=1,\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=dim_inner,\n",
    "            out_channels=dim,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            stride=1,\n",
    "        )\n",
    "\n",
    "        # Init instance normalization\n",
    "        self.instance_norm = nn.InstanceNorm2d(dim)\n",
    "        self.instance_norm2 = nn.InstanceNorm2d(dim_inner)\n",
    "\n",
    "        # Leaky RELU\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "        # Layernorm\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        # Mamba block\n",
    "        self.mamba = MambaBlock(\n",
    "            dim=dim,\n",
    "            depth=depth,\n",
    "            d_state=d_state,\n",
    "            expand=expand,\n",
    "            d_conv=d_conv,\n",
    "            conv_bias=conv_bias,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        \"\"\"\n",
    "        B, C, H, W\n",
    "        \"\"\"\n",
    "        b, c, h, w = x.shape\n",
    "        input = x\n",
    "        print(f\"Input shape: {x.shape}\")\n",
    "\n",
    "        # Apply convolution\n",
    "        x = self.conv1(x)\n",
    "        print(f\"Conv1 shape: {x.shape}\")\n",
    "\n",
    "        # # Instance Normalization\n",
    "        x = self.instance_norm(x) + self.leaky_relu(x)\n",
    "        print(f\"Instance Norm shape: {x.shape}\")\n",
    "\n",
    "        # TODO: Add another residual connection here\n",
    "\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x = self.instance_norm(x) + self.leaky_relu(x)\n",
    "\n",
    "        x = x + input\n",
    "\n",
    "        # # Flatten to B, L, C\n",
    "        x = rearrange(x, \"b c h w -> b (h w) c\")\n",
    "        print(f\"Faltten shape: {x.shape}\")\n",
    "        x = self.norm(x)\n",
    "\n",
    "        # Maybe use a mamba block here then reshape back to B, C, H, W, D\n",
    "        x = self.mamba(x)\n",
    "\n",
    "        # Reshape back to B, C, H, W, D\n",
    "        x = rearrange(x, \"b (h w) c -> b c h w\", h=h, w=w)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 64, 96, 96])\n",
      "Conv1 shape: torch.Size([2, 128, 96, 96])\n",
      "Instance Norm shape: torch.Size([2, 128, 96, 96])\n",
      "Faltten shape: torch.Size([2, 9216, 64])\n",
      "torch.Size([2, 64, 96, 96]) cuda:0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "from einops import rearrange\n",
    "from torch import Tensor, nn\n",
    "import torch\n",
    "\n",
    "from zeta.nn.modules.simple_mamba import MambaBlock\n",
    "\n",
    "\n",
    "img_tensor = torch.randn(2, 64, 96, 96).cuda()\n",
    "\n",
    "# Initialize Mamba block\n",
    "block = UMambaBlock_2D(dim=64, depth=5).cuda()\n",
    "\n",
    "# Forward pass\n",
    "y = block(img_tensor)\n",
    "print(y.shape, y.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from einops import rearrange\n",
    "from torch import Tensor, nn\n",
    "import torch\n",
    "\n",
    "from zeta.nn.modules.u_mamba import UMambaBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 64, 96, 96, 96])\n",
      "Conv1 shape: torch.Size([1, 128, 96, 96, 96])\n",
      "Instance Norm shape: torch.Size([1, 128, 96, 96, 96])\n",
      "Faltten shape: torch.Size([1, 884736, 64])\n",
      "torch.Size([1, 64, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "from einops import rearrange\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from zeta.nn.modules.simple_mamba import MambaBlock\n",
    "\n",
    "\n",
    "class UMambaBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    UMambaBlock is a 5d Mamba block that can be used as a building block for a 5d visual model\n",
    "    From the paper: https://arxiv.org/pdf/2401.04722.pdf\n",
    "\n",
    "    Args:\n",
    "        dim (int): The input dimension.\n",
    "        dim_inner (Optional[int]): The inner dimension. If not provided, it is set to dim * expand.\n",
    "        depth (int): The depth of the Mamba block.\n",
    "        d_state (int): The state dimension. Default is 16.\n",
    "        expand (int): The expansion factor. Default is 2.\n",
    "        dt_rank (Union[int, str]): The rank of the temporal difference (Δ) tensor. Default is \"auto\".\n",
    "        d_conv (int): The dimension of the convolutional kernel. Default is 4.\n",
    "        conv_bias (bool): Whether to include bias in the convolutional layer. Default is True.\n",
    "        bias (bool): Whether to include bias in the linear layers. Default is False.\n",
    "\n",
    "    Examples::\n",
    "        import torch\n",
    "        # img:         B, C, H, W, D\n",
    "        img_tensor = torch.randn(1, 64, 10, 10, 10)\n",
    "\n",
    "        # Initialize Mamba block\n",
    "        block = UMambaBlock(dim=64, depth=1)\n",
    "\n",
    "        # Forward pass\n",
    "        y = block(img_tensor)\n",
    "        print(y.shape)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int = None,\n",
    "        depth: int = 5,\n",
    "        d_state: int = 16,\n",
    "        expand: int = 2,\n",
    "        d_conv: int = 4,\n",
    "        conv_bias: bool = True,\n",
    "        bias: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.depth = depth\n",
    "        self.d_state = d_state\n",
    "        self.expand = expand\n",
    "        self.d_conv = d_conv\n",
    "        self.conv_bias = conv_bias\n",
    "        self.bias = bias\n",
    "\n",
    "        # If dt_rank is not provided, set it to ceil(dim / d_state)\n",
    "        dt_rank = math.ceil(self.dim / 16)\n",
    "        self.dt_rank = dt_rank\n",
    "\n",
    "        # If dim_inner is not provided, set it to dim * expand\n",
    "        dim_inner = dim * expand\n",
    "        self.dim_inner = dim_inner\n",
    "\n",
    "        # If dim_inner is not provided, set it to dim * expand\n",
    "        self.in_proj = nn.Linear(dim, dim_inner, bias=False)\n",
    "        self.out_proj = nn.Linear(dim_inner, dim, bias=False)\n",
    "\n",
    "        # Implement 2d convolutional layer\n",
    "        # 3D depthwise convolution\n",
    "        self.conv1 = nn.Conv3d(\n",
    "            in_channels=dim,\n",
    "            out_channels=dim_inner,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            stride=1,\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv3d(\n",
    "            in_channels=dim_inner,\n",
    "            out_channels=dim,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            stride=1,\n",
    "        )\n",
    "\n",
    "        # Init instance normalization\n",
    "        self.instance_norm = nn.InstanceNorm3d(dim)\n",
    "        self.instance_norm2 = nn.InstanceNorm3d(dim_inner)\n",
    "\n",
    "        # Leaky RELU\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "        # Layernorm\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        # Mamba block\n",
    "        self.mamba = MambaBlock(\n",
    "            dim=dim,\n",
    "            depth=depth,\n",
    "            d_state=d_state,\n",
    "            expand=expand,\n",
    "            d_conv=d_conv,\n",
    "            conv_bias=conv_bias,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        \"\"\"\n",
    "        B, C, H, W, D\n",
    "        \"\"\"\n",
    "        b, c, h, w, d = x.shape\n",
    "        input = x\n",
    "        print(f\"Input shape: {x.shape}\")\n",
    "\n",
    "        # Apply convolution\n",
    "        x = self.conv1(x)\n",
    "        print(f\"Conv1 shape: {x.shape}\")\n",
    "\n",
    "        # # Instance Normalization\n",
    "        x = self.instance_norm(x) + self.leaky_relu(x)\n",
    "        print(f\"Instance Norm shape: {x.shape}\")\n",
    "\n",
    "        # TODO: Add another residual connection here\n",
    "\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x = self.instance_norm(x) + self.leaky_relu(x)\n",
    "\n",
    "        x = x + input\n",
    "\n",
    "        # # Flatten to B, L, C\n",
    "        x = rearrange(x, \"b c h w d -> b (h w d) c\")\n",
    "        print(f\"Faltten shape: {x.shape}\")\n",
    "        x = self.norm(x)\n",
    "\n",
    "        # Maybe use a mamba block here then reshape back to B, C, H, W, D\n",
    "        x = self.mamba(x)\n",
    "\n",
    "        # Reshape back to B, C, H, W, D\n",
    "        x = rearrange(x, \"b (h w d) c -> b c h w d\", h=h, w=w, d=d)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "import torch\n",
    "        # img:         B, C, H, W, D\n",
    "img_tensor = torch.randn(1, 64, 96, 96, 96)\n",
    "\n",
    "# Initialize Mamba block\n",
    "block = UMambaBlock(dim=64, depth=1)\n",
    "\n",
    "# Forward pass\n",
    "y = block(img_tensor)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 300\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    299\u001b[0m model \u001b[38;5;241m=\u001b[39m Mamba(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m--> 300\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28mprint\u001b[39m(out)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\.conda\\envs\\infill\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\.conda\\envs\\infill\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[23], line 290\u001b[0m, in \u001b[0;36mMamba.forward\u001b[1;34m(self, x, context)\u001b[0m\n\u001b[0;32m    287\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, projected_img], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmamba_layers:\n\u001b[1;32m--> 290\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m x\n\u001b[0;32m    292\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_f(x)\n\u001b[0;32m    293\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(x)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\.conda\\envs\\infill\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\.conda\\envs\\infill\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[23], line 107\u001b[0m, in \u001b[0;36mMambaBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor):\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mamba block forward. This looks the same as Figure 3 in Section 3.4 in the Mamba paper [1].\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m     (b, l, d) \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    109\u001b[0m     x_and_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj(x)  \u001b[38;5;66;03m# shape (b, l, 2 * d_in)\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     x_and_res \u001b[38;5;241m=\u001b[39m rearrange(x_and_res, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb l x -> b x l\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from einops import einsum, rearrange, repeat\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from zeta.nn.modules.rms_norm import RMSNorm\n",
    "from zeta.utils import exists\n",
    "\n",
    "\n",
    "class MambaBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Initialize a single Mamba block.\n",
    "\n",
    "    Args:\n",
    "        dim (int): The input dimension.\n",
    "        dim_inner (Optional[int]): The inner dimension. If not provided, it is set to dim * expand.\n",
    "        depth (int): The depth of the Mamba block.\n",
    "        d_state (int): The state dimension. Default is 16.\n",
    "        expand (int): The expansion factor. Default is 2.\n",
    "        dt_rank (Union[int, str]): The rank of the temporal difference (Δ) tensor. Default is \"auto\".\n",
    "        d_conv (int): The dimension of the convolutional kernel. Default is 4.\n",
    "        conv_bias (bool): Whether to include bias in the convolutional layer. Default is True.\n",
    "        bias (bool): Whether to include bias in the linear layers. Default is False.\n",
    "\n",
    "    Examples:\n",
    "        >>> import torch\n",
    "        >>> from zeta.nn.modules.simple_mamba import MambaBlock\n",
    "        >>> block = MambaBlock(dim=64, depth=1)\n",
    "        >>> x = torch.randn(1, 10, 64)\n",
    "        >>> y = block(x)\n",
    "        >>> y.shape\n",
    "        torch.Size([1, 10, 64])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int = None,\n",
    "        depth: int = 5,\n",
    "        d_state: int = 16,\n",
    "        expand: int = 2,\n",
    "        d_conv: int = 4,\n",
    "        conv_bias: bool = True,\n",
    "        bias: bool = False,\n",
    "    ):\n",
    "        \"\"\"A single Mamba block, as described in Figure 3 in Section 3.4 in the Mamba paper [1].\"\"\"\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.depth = depth\n",
    "        self.d_state = d_state\n",
    "        self.expand = expand\n",
    "        self.d_conv = d_conv\n",
    "        self.conv_bias = conv_bias\n",
    "        self.bias = bias\n",
    "\n",
    "        # If dt_rank is not provided, set it to ceil(dim / d_state)\n",
    "        dt_rank = math.ceil(self.dim / 16)\n",
    "        self.dt_rank = dt_rank\n",
    "\n",
    "        # If dim_inner is not provided, set it to dim * expand\n",
    "        dim_inner = dim * expand\n",
    "        self.dim_inner = dim_inner\n",
    "\n",
    "        # If dim_inner is not provided, set it to dim * expand\n",
    "        self.in_proj = nn.Linear(dim, dim_inner * 2, bias=bias)\n",
    "\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=dim_inner,\n",
    "            out_channels=dim_inner,\n",
    "            bias=conv_bias,\n",
    "            kernel_size=d_conv,\n",
    "            groups=dim_inner,\n",
    "            padding=d_conv - 1,\n",
    "        )\n",
    "\n",
    "        # x_proj takes in `x` and outputs the input-specific Δ, B, C\n",
    "        self.x_proj = nn.Linear(\n",
    "            dim_inner, dt_rank + self.d_state * 2, bias=False\n",
    "        )\n",
    "\n",
    "        # dt_proj projects Δ from dt_rank to d_in\n",
    "        self.dt_proj = nn.Linear(dt_rank, dim_inner, bias=True)\n",
    "\n",
    "        A = repeat(torch.arange(1, self.d_state + 1), \"n -> d n\", d=dim_inner)\n",
    "        self.A_log = nn.Parameter(torch.log(A))\n",
    "        self.D = nn.Parameter(torch.ones(dim_inner))\n",
    "        self.out_proj = nn.Linear(dim_inner, dim, bias=bias)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        \"\"\"Mamba block forward. This looks the same as Figure 3 in Section 3.4 in the Mamba paper [1].\n",
    "\n",
    "        Args:\n",
    "            x: shape (b, l, d)    (See Glossary at top for definitions of b, l, d_in, n...)\n",
    "\n",
    "        Returns:\n",
    "            output: shape (b, l, d)\n",
    "\n",
    "\n",
    "        Official Implementation:\n",
    "            class Mamba, https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L119\n",
    "            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n",
    "\n",
    "        \"\"\"\n",
    "        (b, l, d) = x.shape\n",
    "\n",
    "        x_and_res = self.in_proj(x)  # shape (b, l, 2 * d_in)\n",
    "        x_and_res = rearrange(x_and_res, \"b l x -> b x l\")\n",
    "        (x, res) = x_and_res.split(\n",
    "            split_size=[self.dim_inner, self.dim_inner], dim=1\n",
    "        )\n",
    "\n",
    "        x = self.conv1d(x)[:, :, :l]\n",
    "        x = F.silu(x)\n",
    "\n",
    "        y = self.ssm(x)\n",
    "\n",
    "        y = y * F.silu(res)\n",
    "\n",
    "        output = self.out_proj(rearrange(y, \"b dim l -> b l dim\"))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def ssm(self, x: Tensor):\n",
    "        \"\"\"Runs the SSM. See:\n",
    "            - Algorithm 2 in Section 3.2 in the Mamba paper [1]\n",
    "            - run_SSM(A, B, C, u) in The Annotated S4 [2]\n",
    "\n",
    "        Args:\n",
    "            x: shape (b, d_in, l)    (See Glossary at top for definitions of b, l, d_in, n...)\n",
    "\n",
    "        Returns:\n",
    "            output: shape (b, d_in, l)\n",
    "\n",
    "        Official Implementation:\n",
    "            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n",
    "\n",
    "        \"\"\"\n",
    "        (d_in, n) = self.A_log.shape\n",
    "\n",
    "        # Compute ∆ A B C D, the state space parameters.\n",
    "        #     A, D are input independent\n",
    "        #     ∆, B, C are input-dependent (this is a key difference between Mamba and the linear time invariant S4)\n",
    "\n",
    "        A = -torch.exp(self.A_log.float())  # shape (d_in, n)\n",
    "        D = self.D.float()\n",
    "\n",
    "        x_dbl = rearrange(x, \"b d l -> b l d\")\n",
    "        x_dbl = self.x_proj(x_dbl)  # (b, l, dt_rank + 2*n)\n",
    "\n",
    "        (delta, B, C) = x_dbl.split(\n",
    "            split_size=[self.dt_rank, n, n], dim=-1\n",
    "        )  # delta: (b, l, dt_rank). B, C: (b, l, n)\n",
    "        delta = F.softplus(self.dt_proj(delta))  # (b, l, d_in)\n",
    "\n",
    "        y = self.selective_scan(\n",
    "            x, delta, A, B, C, D\n",
    "        )  # This is similar to run_SSM(A, B, C, u) in The Annotated S4 [2]\n",
    "\n",
    "        return y\n",
    "\n",
    "    def selective_scan(self, u, delta, A, B, C, D):\n",
    "        \"\"\"Does selective scan algorithm. See:\n",
    "            - Section 2 State Space Models in the Mamba paper [1]\n",
    "            - Algorithm 2 in Section 3.2 in the Mamba paper [1]\n",
    "            - run_SSM(A, B, C, u) in The Annotated S4 [2]\n",
    "\n",
    "        This is the classic discrete state space formula:\n",
    "            x(t + 1) = Ax(t) + Bu(t)\n",
    "            y(t)     = Cx(t) + Du(t)\n",
    "        except B and C (and the step size delta, which is used for discretization) are dependent on the input x(t).\n",
    "\n",
    "        Args:\n",
    "            u: shape (b, d_in, l)    (See Glossary at top for definitions of b, l, d_in, n...)\n",
    "            delta: shape (b, l, d_in)\n",
    "            A: shape (d_in, n)\n",
    "            B: shape (b, l, n)\n",
    "            C: shape (b, l, n)\n",
    "            D: shape (d_in,)\n",
    "\n",
    "        Returns:\n",
    "            output: shape (b, d_in, l)\n",
    "\n",
    "        Official Implementation:\n",
    "            selective_scan_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L86\n",
    "            Note: I refactored some parts out of `selective_scan_ref` out, so the functionality doesn't match exactly.\n",
    "\n",
    "        \"\"\"\n",
    "        (b, d_in, l) = u.shape\n",
    "        n = A.shape[1]\n",
    "\n",
    "        # Discretize continuous parameters (Δ, A, B)  (see Section 2 Equation 4 in the Mamba paper [1])\n",
    "        # Note that B is parameterized directly\n",
    "        deltaA = torch.exp(einsum(delta, A, \"b l d_in, d_in n -> b d_in l n\"))\n",
    "        deltaB_u = einsum(\n",
    "            delta, B, u, \"b l d_in, b l n, b d_in l -> b d_in l n\"\n",
    "        )\n",
    "\n",
    "        # Perform selective scan (see scan_SSM() in The Annotated S4 [2])\n",
    "        x = torch.zeros((b, d_in, n), device=next(self.parameters()).device)\n",
    "        ys = []\n",
    "        for i in range(l):\n",
    "            x = deltaA[:, :, i] * x + deltaB_u[:, :, i]\n",
    "            y = einsum(x, C[:, i, :], \"b d_in n , b n -> b d_in\")\n",
    "            ys.append(y)\n",
    "        y = torch.stack(ys, dim=2)  # (b d_in l)\n",
    "\n",
    "        if D is not None:\n",
    "            y = y + u * rearrange(D, \"d_in -> d_in 1\")\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class Mamba(nn.Module):\n",
    "    \"\"\"Mamba model.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): The size of the vocabulary.\n",
    "        dim (int): The input dimension.\n",
    "        depth (int): The depth of the Mamba block.\n",
    "        d_state (int): The state dimension. Default is 16.\n",
    "        expand (int): The expansion factor. Default is 2.\n",
    "        dt_rank (Union[int, str]): The rank of the temporal difference (Δ) tensor. Default is \"auto\".\n",
    "        d_conv (int): The dimension of the convolutional kernel. Default is 4.\n",
    "\n",
    "    Examples:\n",
    "    x = torch.randint(0, 16, (1, 64))\n",
    "    model = Mamba(16, 64, 5, 16)\n",
    "    out = model(x)\n",
    "    print(out)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int = None,\n",
    "        dim: int = None,\n",
    "        depth: int = 5,\n",
    "        d_state: int = 16,\n",
    "        img_dim: int = 64,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Full Mamba model.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, dim)\n",
    "        self.norm_f = RMSNorm(dim)\n",
    "        self.lm_head = nn.Linear(dim, vocab_size, bias=False)\n",
    "        self.lm_head.weight = self.embedding.weight\n",
    "        self.mamba_layers = nn.ModuleList(\n",
    "            [\n",
    "                MambaBlock(\n",
    "                    dim=dim, depth=depth, d_state=d_state, *args, **kwargs\n",
    "                )\n",
    "                for _ in range(depth)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Projection for img\n",
    "        self.img_proj = nn.Linear(img_dim, dim)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        context: Tensor = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (long tensor): shape (b, l)    (See Glossary at top for definitions of b, l, d_in, n...)\n",
    "\n",
    "        Returns:\n",
    "            logits: shape (b, l, vocab_size)\n",
    "\n",
    "        Official Implementation:\n",
    "            class MambaLMHeadModel, https://github.com/state-spaces/mamba/blob/main/mamba_ssm/models/mixer_seq_simple.py#L173\n",
    "\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if exists(context):\n",
    "            # Project the image\n",
    "            projected_img = self.img_proj(context)\n",
    "\n",
    "            # Concatenate the image and text\n",
    "            x = torch.cat([x, projected_img], dim=1)\n",
    "\n",
    "        for layer in self.mamba_layers:\n",
    "            x = layer(self.norm_f(x)) + x\n",
    "\n",
    "        x = self.norm_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        return logits\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
